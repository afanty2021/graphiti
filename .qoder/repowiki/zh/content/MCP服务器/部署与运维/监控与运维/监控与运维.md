# 监控与运维

<cite>
**本文档引用的文件**
- [main.py](file://mcp_server/main.py)
- [graphiti_mcp_server.py](file://mcp_server/src/graphiti_mcp_server.py)
- [schema.py](file://mcp_server/src/config/schema.py)
- [config.yaml](file://mcp_server/config/config.yaml)
- [Dockerfile](file://mcp_server/docker/Dockerfile)
- [docker-compose.yml](file://mcp_server/docker/docker-compose.yml)
</cite>

## 目录
1. [健康检查端点](#健康检查端点)
2. [日志管理方案](#日志管理方案)
3. [性能监控指标](#性能监控指标)
4. [SEMAPHORE_LIMIT参数分析](#semaphore_limit参数分析)
5. [常见故障诊断](#常见故障诊断)

## 健康检查端点

MCP服务器实现了标准的健康检查端点`/health`，用于与Kubernetes、Docker Swarm等容器编排系统集成。该端点通过HTTP GET方法暴露，返回服务器的基本健康状态。

健康检查端点的实现位于`graphiti_mcp_server.py`文件中，使用`@mcp.custom_route`装饰器定义。当收到健康检查请求时，服务器会返回包含状态信息的JSON响应，表明服务处于健康运行状态。

在Kubernetes环境中，可以通过配置liveness和readiness探针来使用此端点：

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 15
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /health
    port: 8000
  initialDelaySeconds: 5
  periodSeconds: 5
```

对于Docker Swarm，可以在服务配置中使用healthcheck指令：

```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  interval: 10s
  timeout: 5s
  retries: 3
```

此外，服务器还提供了`get_status`工具函数，可以检查数据库连接状态，为更深入的健康评估提供支持。

**Section sources**
- [graphiti_mcp_server.py](file://mcp_server/src/graphiti_mcp_server.py#L756-L759)

## 日志管理方案

MCP服务器采用结构化日志输出方案，便于集中式日志收集和分析。日志配置在`graphiti_mcp_server.py`文件中定义，使用Python标准库的logging模块。

日志格式包含时间戳、日志级别、模块名称和消息内容，符合以下格式：
```
%(asctime)s - %(name)s - %(levelname)s - %(message)s
```

日志级别设置如下：
- 根日志记录器：INFO级别
- uvicorn访问日志：WARNING级别（减少访问日志噪音）
- MCP服务器内部日志：WARNING级别

服务器支持将日志输出到标准错误流，便于容器环境下的日志收集。建议使用ELK（Elasticsearch、Logstash、Kibana）栈进行集中式日志管理。

在Docker部署中，可以通过卷挂载将日志持久化到`/var/log/graphiti`目录。Logstash可以配置为监控此目录，将日志发送到Elasticsearch进行存储和索引，然后通过Kibana进行可视化分析。

**Section sources**
- [graphiti_mcp_server.py](file://mcp_server/src/graphiti_mcp_server.py#L78-L94)

## 性能监控指标

MCP服务器的关键性能监控指标包括请求延迟、错误率和并发处理能力。

请求延迟主要受LLM调用的影响，因为每个episode处理涉及多个LLM调用（实体提取、去重等）。可以通过监控`add_memory`等工具函数的执行时间来评估请求延迟。

错误率监控重点关注LLM提供商的速率限制错误（HTTP 429）。服务器日志会记录这些错误，便于分析和调整并发设置。建议监控以下错误类型：
- LLM提供商速率限制错误
- 数据库连接错误
- 配置错误

并发处理能力由`SEMAPHORE_LIMIT`环境变量控制，限制同时处理的episodes数量。实际的LLM请求数会更高，因为每个episode处理涉及多个LLM调用。

建议使用Prometheus和Grafana等监控工具收集和可视化这些指标。可以通过应用程序指标端点或日志分析来获取这些数据。

**Section sources**
- [graphiti_mcp_server.py](file://mcp_server/src/graphiti_mcp_server.py#L48-L75)

## SEMAPHORE_LIMIT参数分析

`SEMAPHORE_LIMIT`参数是MCP服务器性能调优的关键配置，控制同时处理的episodes数量。该参数在`graphiti_mcp_server.py`文件中定义，默认值为10。

### 影响分析

`SEMAPHORE_LIMIT`直接影响系统的吞吐量和资源利用率：
- 值过高：可能导致LLM提供商的速率限制错误（429），增加成本
- 值过低：导致处理吞吐量不足，API配额利用率低

每个episode处理涉及多个LLM调用，因此实际的LLM请求数是`SEMAPHORE_LIMIT`值的数倍。

### 调优建议

根据LLM提供商的速率限制，建议的`SEMAPHORE_LIMIT`值如下：

| LLM提供商 | 速率限制（每分钟） | 建议SEMAPHORE_LIMIT |
|----------|------------------|-------------------|
| OpenAI 免费层 | 3 RPM | 1-2 |
| OpenAI 第二层 | 60 RPM | 5-8 |
| OpenAI 第三层 | 500 RPM | 10-15 |
| OpenAI 第四层 | 5,000 RPM | 20-50 |
| Anthropic（默认） | 50 RPM | 5-8 |
| Anthropic（高级层） | 1,000 RPM | 15-30 |

### 监控指标

调优时应监控以下指标：
- 日志中的速率限制错误（429）
- episode处理时间
- LLM提供商仪表板中的实际请求速率

在`config.yaml`配置文件中，可以通过环境变量设置此参数：
```yaml
environment:
  - SEMAPHORE_LIMIT=${SEMAPHORE_LIMIT:-10}
```

**Section sources**
- [graphiti_mcp_server.py](file://mcp_server/src/graphiti_mcp_server.py#L48-L75)
- [config.yaml](file://mcp_server/config/config.yaml#L23)

## 常见故障诊断

### 数据库连接失败

当数据库无法连接时，服务器会抛出详细的错误信息，并提供相应的解决方案：

- **FalkorDB**: 检查是否已启动`docker compose up`
- **Neo4j**: 检查是否已启动`docker compose -f docker/docker-compose-neo4j.yml up`

解决方案包括启动相应的Docker容器或确保数据库服务正在运行。

### LLM提供商认证错误

如果LLM提供商的API密钥未正确配置，服务器会记录警告信息。检查相应的环境变量（如`OPENAI_API_KEY`、`ANTHROPIC_API_KEY`等）是否已正确设置。

### 配置文件错误

配置文件`config.yaml`支持环境变量扩展。如果配置不正确，服务器可能无法启动。检查环境变量是否已正确加载，特别是数据库连接信息和LLM提供商配置。

### 高并发错误

当出现频繁的429错误时，表明`SEMAPHORE_LIMIT`设置过高。根据LLM提供商的速率限制调整此参数，并监控实际的请求速率。

### 容器健康检查失败

在Docker部署中，如果健康检查失败，检查：
- FalkorDB是否已正确启动
- 端口映射是否正确
- 环境变量是否已正确传递

通过分析服务器日志，可以快速定位和解决这些常见问题。

**Section sources**
- [graphiti_mcp_server.py](file://mcp_server/src/graphiti_mcp_server.py#L247-L277)
- [Dockerfile](file://mcp_server/docker/Dockerfile#L132-L133)
- [docker-compose.yml](file://mcp_server/docker/docker-compose.yml#L33-L38)