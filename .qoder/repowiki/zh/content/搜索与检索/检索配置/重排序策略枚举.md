# 重排序策略枚举

<cite>
**本文档中引用的文件**  
- [search_config.py](file://graphiti_core/search/search_config.py)
- [search_utils.py](file://graphiti_core/search/search_utils.py)
- [search.py](file://graphiti_core/search/search.py)
- [client.py](file://graphiti_core/cross_encoder/client.py)
- [bge_reranker_client.py](file://graphiti_core/cross_encoder/bge_reranker_client.py)
- [gemini_reranker_client.py](file://graphiti_core/cross_encoder/gemini_reranker_client.py)
- [openai_reranker_client.py](file://graphiti_core/cross_encoder/openai_reranker_client.py)
</cite>

## 目录
1. [引言](#引言)
2. [重排序器实现机制与业务含义](#重排序器实现机制与业务含义)
3. [RRF（倒数排名融合）原理与优势](#rrf倒数排名融合原理与优势)
4. [MMR（最大边际相关性）与多样性控制](#mmr最大边际相关性与多样性控制)
5. [图拓扑特征增强：node_distance与episode_mentions](#图拓扑特征增强node_distance与episode_mentions)
6. [Cross-Encoder与LLM精细化打分](#cross-encoder与llm精细化打分)
7. [调参建议与输出分布影响分析](#调参建议与输出分布影响分析)
8. [结论](#结论)

## 引言
本文档深入剖析Graphiti系统中NodeReranker、EdgeReranker、EpisodeReranker和CommunityReranker的实现机制与业务含义。重点解析RRF（倒数排名融合）的数学原理、MMR（最大边际相关性）在多样性控制中的作用、node_distance和episode_mentions作为图拓扑特征的排序增强机制，以及cross_encoder如何利用大语言模型（LLM）进行精细化相关性打分。同时提供各策略的调参建议及其对输出分布的影响分析。

## 重排序器实现机制与业务含义

在Graphiti系统中，重排序器（Reranker）是搜索流程中的关键组件，用于对初步检索结果进行重新排序，以提升结果的相关性、多样性和上下文一致性。系统为不同类型的图元素（节点、边、片段、社区）提供了专门的重排序策略。

根据`search_config.py`中的定义，系统支持以下四类重排序器：

- **NodeReranker**：用于对实体节点（EntityNode）进行重排序。
- **EdgeReranker**：用于对实体边（EntityEdge）进行重排序。
- **EpisodeReranker**：用于对片段节点（EpisodicNode）进行重排序。
- **CommunityReranker**：用于对社区节点（CommunityNode）进行重排序。

每种重排序器都支持多种策略，包括`rrf`、`mmr`、`cross_encoder`等，允许用户根据具体场景灵活配置。

**Section sources**
- [search_config.py](file://graphiti_core/search/search_config.py#L52-L77)

## RRF（倒数排名融合）原理与优势

### 数学原理
倒数排名融合（Reciprocal Rank Fusion, RRF）是一种简单而有效的多源结果合并算法。其核心思想是：一个结果在多个独立排序列表中排名越靠前，其综合得分就越高。

其计算公式如下：
```
RRF Score = Σ (1 / (k + rank_i))
```
其中：
- `rank_i` 是某结果在第 `i` 个排序列表中的排名（从1开始）。
- `k` 是一个常数（通常为60），用于控制排名衰减的速度。

在Graphiti中，RRF被用于合并来自不同搜索方法（如BM25、向量相似度、BFS）的结果。例如，当配置了`bm25`和`cosine_similarity`两种搜索方法时，系统会分别得到两个排序列表，然后通过RRF将它们融合成一个最终的排序。

### 多源结果合并优势
- **鲁棒性强**：不依赖于任何单一排序算法的假设，能有效结合不同算法的优势。
- **无需参数调优**：相比其他融合方法，RRF几乎不需要调参，使用简单。
- **提升召回率**：能将不同算法检索到的优质结果都纳入考虑，避免遗漏。

在代码中，`rrf`函数位于`search_utils.py`，它接收一个包含多个排序列表的列表，计算每个结果的RRF得分，并返回按得分降序排列的结果ID列表和得分列表。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1732-L1749)
- [search.py](file://graphiti_core/search/search.py#L62)

## MMR（最大边际相关性）与多样性控制

### 作用机制
最大边际相关性（Maximal Marginal Relevance, MMR）是一种旨在平衡结果相关性与多样性的重排序算法。其核心思想是在保证与查询相关的同时，尽量选择与已选结果差异较大的新结果。

其计算公式如下：
```
MMR Score = λ * Sim(Query, Candidate) - (1 - λ) * max(Sim(Candidate, Selected))
```
其中：
- `Sim(Query, Candidate)` 是候选结果与查询的相关性得分（如余弦相似度）。
- `max(Sim(Candidate, Selected))` 是候选结果与已选结果集合中最高相似度。
- `λ` 是一个介于0和1之间的超参数，用于控制相关性与多样性的权衡。

当`λ`接近1时，更注重相关性；当`λ`接近0时，更注重多样性。

### 在Graphiti中的应用
在Graphiti中，MMR被用作`NodeReranker`、`EdgeReranker`和`CommunityReranker`的一种策略。系统首先计算所有候选结果与查询向量的相似度，然后通过`maximal_marginal_relevance`函数进行MMR重排序。

该函数位于`search_utils.py`，它构建一个候选结果间的相似度矩阵，然后迭代地选择MMR得分最高的结果，直到所有结果都被排序。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1838-L1876)
- [search.py](file://graphiti_core/search/search.py#L57)

## 图拓扑特征增强：node_distance与episode_mentions

### node_distance
`node_distance`重排序器利用图的拓扑结构信息，根据候选节点与指定中心节点（`center_node_uuid`）的距离来调整排序。其业务含义是：在图谱中与核心节点直接相连的节点，通常具有更高的相关性或重要性。

实现上，该函数首先通过Cypher查询找出与中心节点有直接关系的候选节点，并赋予它们较高的分数（1.0），其余节点则被赋予较低分数（无穷大）。然后，根据分数的倒数进行排序，确保距离最近的节点排在最前面。

此策略特别适用于“以某人为中心”的社交网络分析或“以某事件为核心”的知识图谱探索。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1750-L1802)
- [search.py](file://graphiti_core/search/search.py#L276-L300)

### episode_mentions
`episode_mentions`重排序器基于“被提及次数”来衡量节点或边的重要性。其业务含义是：在多个片段（episode）中被反复提及的实体或关系，往往更关键、更值得关注。

该函数首先使用RRF对输入结果进行初步排序，然后通过Cypher查询统计每个节点被多少个片段提及（`count(*)`），并根据提及次数进行最终排序。提及次数越多，排名越靠前。

此策略能有效识别出跨时间、跨事件的“高频”实体，增强结果的上下文覆盖广度。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1804-L1835)
- [search.py](file://graphiti_core/search/search.py#L400-L403)

## Cross-Encoder与LLM精细化打分

### 实现机制
Cross-Encoder是一种基于深度学习的相关性排序模型。与仅对查询和文档分别编码的双塔模型不同，Cross-Encoder将查询和文档拼接在一起进行联合编码，能捕捉更细粒度的交互信息，因此排序精度更高。

在Graphiti中，`cross_encoder`模块提供了与外部重排序服务的接口。系统定义了`CrossEncoderClient`抽象基类，具体的实现（如`BGERerankerClient`、`GeminiRerankerClient`、`OpenAIRerankerClient`）负责调用相应的API。

当使用`cross_encoder`作为重排序策略时，系统会将查询和候选结果的文本内容（如节点名称、边事实、片段内容）发送给重排序服务，服务返回一个相关性得分列表，系统据此对结果进行排序。

### 业务含义
- **精细化打分**：利用LLM强大的语义理解能力，对查询与候选结果的语义匹配度进行深度评估。
- **处理复杂查询**：对于需要深层推理或上下文理解的复杂查询，Cross-Encoder的表现通常优于传统的关键词或向量匹配方法。
- **提升排序质量**：作为重排序的最后一步，能显著提升Top-K结果的准确率。

**Section sources**
- [client.py](file://graphiti_core/cross_encoder/client.py#L20-L40)
- [bge_reranker_client.py](file://graphiti_core/cross_encoder/bge_reranker_client.py#L33)
- [gemini_reranker_client.py](file://graphiti_core/cross_encoder/gemini_reranker_client.py#L42)
- [search.py](file://graphiti_core/search/search.py#L269-L275)

## 调参建议与输出分布影响分析

### mmr_lambda
- **参数含义**：控制MMR算法中相关性与多样性的权衡。
- **调参建议**：
  - `mmr_lambda = 1.0`：完全忽略多样性，等同于按相关性得分排序。适用于需要最相关结果的场景。
  - `mmr_lambda = 0.5`（默认值）：平衡相关性与多样性。适用于大多数通用搜索场景。
  - `mmr_lambda = 0.1`：极度强调多样性。适用于探索性搜索，希望看到不同角度的结果。
- **输出分布影响**：`λ`值越小，输出结果的多样性越高，但平均相关性可能下降；`λ`值越大，结果越集中于少数高相关性项，可能导致结果冗余。

### reranker_min_score
- **参数含义**：重排序后的最低得分阈值，低于此阈值的结果将被过滤。
- **调参建议**：根据具体重排序器的得分范围进行调整。例如，RRF得分范围为(0, N]（N为结果列表数量），MMR得分范围较广，Cross-Encoder得分通常在[0,1]或[1,100]之间。
- **输出分布影响**：提高阈值会减少返回结果数量，但能保证结果质量；降低阈值会增加召回，但可能引入噪声。

### sim_min_score
- **参数含义**：向量相似度搜索的最低相似度阈值。
- **调参建议**：默认值为0.6。对于要求高精度的场景可提高至0.7-0.8；对于探索性搜索可降低至0.5。
- **输出分布影响**：直接影响初始检索结果的数量和质量，是控制搜索“精度-召回”平衡的第一道关卡。

**Section sources**
- [search_config.py](file://graphiti_core/search/search_config.py#L25-L26)
- [search.py](file://graphiti_core/search/search.py#L84-L85)

## 结论
Graphiti系统通过提供多样化的重排序策略，实现了对图谱搜索结果的精细化控制。RRF、MMR、拓扑特征和Cross-Encoder等策略各有侧重，用户可根据具体业务需求进行组合配置。深入理解各策略的原理和参数影响，有助于优化搜索效果，提升知识发现的效率和质量。