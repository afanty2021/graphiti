# 结果重排序

<cite>
**本文档中引用的文件**   
- [client.py](file://graphiti_core/cross_encoder/client.py)
- [openai_reranker_client.py](file://graphiti_core/cross_encoder/openai_reranker_client.py)
- [bge_reranker_client.py](file://graphiti_core/cross_encoder/bge_reranker_client.py)
- [gemini_reranker_client.py](file://graphiti_core/cross_encoder/gemini_reranker_client.py)
- [search.py](file://graphiti_core/search/search.py)
- [search_config.py](file://graphiti_core/search/search_config.py)
- [search_utils.py](file://graphiti_core/search/search_utils.py)
</cite>

## 目录
1. [引言](#引言)
2. [重排序策略概述](#重排序策略概述)
3. [RRF（互逆排名融合）](#rrf互逆排名融合)
4. [MMR（最大边际相关性）](#mmr最大边际相关性)
5. [cross_encoder重排序器](#cross_encoder重排序器)
6. [node_distance重排序器](#node_distance重排序器)
7. [episode_mentions重排序器](#episode_mentions重排序器)
8. [reranker_min_score参数](#reranker_min_score参数)
9. [性能影响与调优建议](#性能影响与调优建议)
10. [实际应用示例](#实际应用示例)

## 引言
本文档深入探讨Graphiti系统中的结果重排序机制。重排序是检索流程中的关键步骤，用于对从图数据库中检索到的初步结果进行重新排序和优化，以提高结果的相关性和质量。系统支持多种重排序策略，包括RRF（互逆排名融合）、MMR（最大边际相关性）、基于cross_encoder的模型、node_distance和episode_mentions等。这些策略可以针对边（Edge）、节点（Node）、片段（Episode）和社区（Community）等不同类型的图元素进行配置和应用。

## 重排序策略概述
在Graphiti中，重排序（Reranking）是搜索流程的最后一步，发生在从图数据库执行多种搜索方法（如全文搜索、向量相似性搜索、广度优先搜索）获取初步结果之后。系统通过`SearchConfig`对象配置重排序策略，该对象为每种图元素类型（边、节点、片段、社区）定义了独立的`SearchConfig`。每种配置都包含一个`reranker`字段，用于指定具体的重排序算法。

**Section sources**
- [search_config.py](file://graphiti_core/search/search_config.py#L53-L78)
- [search.py](file://graphiti_core/search/search.py#L68-L183)

## RRF（互逆排名融合）

### 工作原理
RRF（Reciprocal Rank Fusion）是一种简单而有效的排名融合算法，用于合并来自多个不同搜索方法的结果。其核心思想是：一个项目在多个独立列表中排名越靠前，其综合相关性得分就越高。

该算法的数学原理如下：
1.  对于每个候选项目（如节点UUID），计算其在每一个搜索结果列表中的排名（rank）。
2.  使用公式 `score = 1 / (rank + k)` 计算该项目在每个列表中的得分，其中 `k` 是一个常数（通常为1），用于避免除零错误。
3.  将该项目在所有列表中的得分相加，得到其最终的RRF得分。
4.  根据最终得分对所有候选项目进行降序排序。

在Graphiti中，RRF被广泛用作基础重排序器。例如，当配置了`bm25`和`cosine_similarity`两种搜索方法时，系统会分别执行这两种搜索，得到两个结果列表，然后使用RRF算法将这两个列表融合，生成一个综合排名。

### 使用场景
*   **多方法融合**：当需要结合不同搜索方法的优势时（如结合关键词匹配的精确性和向量搜索的语义理解能力）。
*   **提高召回率**：通过融合多个列表，可以减少因单一方法遗漏相关结果的风险。
*   **作为预处理步骤**：在`node_distance`和`episode_mentions`等更复杂的重排序器中，RRF常被用作初步排序，以缩小后续计算的范围。

### 调优建议
*   `k` 值通常保持默认（1），调整空间不大。
*   确保参与融合的搜索方法具有互补性，避免融合多个高度相似的结果列表。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1732-L1748)
- [search.py](file://graphiti_core/search/search.py#L255-L258)

## MMR（最大边际相关性）

### 工作原理
MMR（Maximal Marginal Relevance）旨在在结果列表中平衡**相关性**和**多样性**。它不仅考虑项目与查询的相关性，还考虑项目与已选项目之间的相似性，以避免返回大量内容重复的结果。

其数学原理基于一个权衡公式：
`MMR得分 = λ * QuerySimilarity - (1 - λ) * MaxDocSimilarity`
其中：
*   `QuerySimilarity` 是候选项目与查询向量的余弦相似度。
*   `MaxDocSimilarity` 是候选项目与当前已选结果列表中所有项目之间的最大余弦相似度。
*   `λ` 是一个介于0和1之间的超参数，用于控制相关性与多样性的权重。

算法流程如下：
1.  选择与查询最相关的项目作为第一个结果。
2.  对于剩余的每个候选项目，计算其MMR得分。
3.  选择MMR得分最高的项目加入结果列表。
4.  重复步骤2-3，直到达到所需的结果数量。

### 使用场景
*   **需要多样化结果**：当用户查询可能对应多个不同方面的答案时（例如，“苹果”可以指水果或公司）。
*   **防止结果冗余**：当原始搜索结果包含大量语义相近的项目时。

### 调优建议
*   **`mmr_lambda` 参数**：这是MMR的核心调优参数。
    *   `λ` 接近1：更注重相关性，结果可能更集中。
    *   `λ` 接近0：更注重多样性，结果范围更广但可能包含相关性较低的项目。
*   默认值通常为0.5，可根据具体应用场景调整。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1838-L1876)
- [search.py](file://graphiti_core/search/search.py#L259-L268)

## cross_encoder重排序器

### 工作原理
`cross_encoder`是一种基于深度学习的重排序方法，它通过一个专门的模型（交叉编码器）来精确评估查询与每个候选项目之间的相关性。与双编码器（将查询和文档分别编码后计算相似度）不同，交叉编码器会将查询和文档拼接在一起进行联合编码，从而能捕捉更细粒度的交互信息，通常能提供更准确的排序。

在Graphiti中，`cross_encoder`通过一个抽象基类`CrossEncoderClient`实现，支持多种后端：

1.  **`BGERerankerClient`**：
    *   使用本地的`BAAI/bge-reranker-v2-m3`模型。
    *   将查询和每个候选项目（如节点名称、边事实）组成一个输入对 `[query, passage]`。
    *   模型直接输出一个相关性得分，系统根据得分排序。

2.  **`OpenAIRerankerClient`**：
    *   利用OpenAI API，通过一个巧妙的提示工程（Prompt Engineering）来模拟重排序。
    *   对每个候选项目，构造一个提示，要求模型判断其是否与查询相关，并返回"True"或"False"。
    *   利用API返回的logprobs（对数概率）来量化相关性。"True"的概率越高，得分越高。

3.  **`GeminiRerankerClient`**：
    *   使用Google Gemini API。
    *   由于Gemini API不支持logprobs，该客户端采用直接评分的方式。
    *   对每个候选项目，提示模型在0-100的范围内打分。
    *   将分数归一化到[0,1]区间作为最终得分。

### 使用场景
*   **追求最高排序精度**：当对结果质量要求极高时，`cross_encoder`通常能提供最佳效果。
*   **复杂语义匹配**：当查询和候选项目之间的关系需要深度语义理解时。

### 调优建议
*   **性能权衡**：`cross_encoder`通常是最耗时的重排序方法，因为它需要对每个候选项目进行一次模型推理（或API调用）。建议先通过其他方法（如RRF）将候选集缩小到一个合理范围（如`limit`的2倍）后再应用。
*   **模型选择**：根据延迟、成本和准确性需求选择合适的后端（本地BGE模型、OpenAI或Gemini）。

**Section sources**
- [client.py](file://graphiti_core/cross_encoder/client.py#L17-L40)
- [bge_reranker_client.py](file://graphiti_core/cross_encoder/bge_reranker_client.py#L34-L54)
- [openai_reranker_client.py](file://graphiti_core/cross_encoder/openai_reranker_client.py#L34-L118)
- [gemini_reranker_client.py](file://graphiti_core/cross_encoder/gemini_reranker_client.py#L43-L147)
- [search.py](file://graphiti_core/search/search.py#L269-L275)

## node_distance重排序器

### 工作原理
`node_distance`重排序器根据候选节点与一个指定的“中心节点”（`center_node_uuid`）的图距离来进行排序。其核心思想是：在图结构中，与中心节点直接相连或距离较近的节点，其相关性可能更高。

其工作流程如下：
1.  首先使用RRF对所有候选节点进行初步排序。
2.  在图数据库中查询哪些候选节点与`center_node_uuid`直接相连（即存在`RELATES_TO`关系）。
3.  与中心节点直接相连的节点得分为1，未直接相连的节点得分为无穷大（`inf`）。
4.  根据得分（距离）进行排序，直接相连的节点排在前面。

### 使用场景
*   **上下文感知搜索**：当用户的查询与某个特定实体（中心节点）紧密相关时。例如，在对话系统中，将上一轮提到的实体作为中心节点，可以确保当前回复与上下文保持一致。
*   **局部图探索**：当需要围绕某个核心概念展开搜索时。

### 调优建议
*   必须提供`center_node_uuid`，否则会抛出异常。
*   该重排序器目前只考虑直接连接（距离为1），不支持多跳距离计算。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1751-L1802)
- [search.py](file://graphiti_core/search/search.py#L276-L300)

## episode_mentions重排序器

### 工作原理
`episode_mentions`重排序器根据候选节点被“片段”（Episode）提及的次数来进行排序。其核心假设是：被更多独立事件或上下文（片段）提及的节点，其重要性或相关性更高。

其工作流程如下：
1.  首先使用RRF对所有候选节点进行初步排序。
2.  在图数据库中查询每个候选节点被哪些片段通过`MENTIONS`关系提及。
3.  统计每个节点被提及的次数（`count(*)`）。
4.  根据提及次数进行降序排序。

### 使用场景
*   **识别重要实体**：在知识图谱中，被频繁提及的实体通常是关键人物、地点或概念。
*   **基于上下文的重要性**：当需要找出在当前对话或文档历史中最常被讨论的实体时。

### 调优建议
*   该重排序器依赖于图中存在`EpisodicNode`和`MENTIONS`关系。
*   提及次数是一个简单的计数，未考虑提及的上下文或情感。

**Section sources**
- [search_utils.py](file://graphiti_core/search/search_utils.py#L1805-L1835)
- [search.py](file://graphiti_core/search/search.py#L400-L403)

## reranker_min_score参数

### 过滤低质量结果
`reranker_min_score`是`SearchConfig`中的一个全局参数，用于过滤掉重排序得分低于指定阈值的结果。它在所有重排序器中都发挥作用。

其工作原理非常直接：
*   在任何重排序算法（RRF、MMR、cross_encoder等）计算出每个候选项目的得分后，系统会检查该得分是否大于或等于`reranker_min_score`。
*   只有得分满足条件的项目才会被保留在最终结果列表中。
*   得分低于阈值的项目将被丢弃。

### 作用与影响
*   **提升结果质量**：通过设置一个合理的阈值（如0.5），可以有效过滤掉大量不相关或弱相关的噪声结果。
*   **控制结果数量**：即使`limit`设置为10，如果只有5个结果的得分超过阈值，最终也只会返回5个结果。
*   **默认值**：默认值为0，意味着不进行过滤。用户可以根据具体需求和数据质量调整此值。

**Section sources**
- [search_config.py](file://graphiti_core/search/search_config.py#L118)
- [search.py](file://graphiti_core/search/search.py#L130-L131)

## 性能影响与调优建议

### 不同重排序器的性能影响
*   **轻量级**：`RRF`、`node_distance`、`episode_mentions`。这些操作主要在应用层进行简单的计算或在数据库中执行一次查询，性能开销很小。
*   **中等开销**：`MMR`。需要计算候选项目之间的相似度矩阵，计算复杂度为O(n²)，当候选集较大时会显著增加延迟。
*   **高开销**：`cross_encoder`。无论是调用本地模型还是远程API，对每个候选项目进行推理的成本都很高，是性能瓶颈的主要来源。

### 综合调优建议
1.  **分层过滤**：利用`limit`参数和`reranker_min_score`先缩小候选集，再应用高成本的重排序器。
2.  **组合使用**：可以先用`RRF`融合多种搜索方法，再用`MMR`增加多样性，最后用`cross_encoder`进行精排。
3.  **根据场景选择**：对于实时性要求高的场景，优先选择轻量级重排序器；对于离线或对质量要求极高的场景，可以使用`cross_encoder`。
4.  **监控与测试**：在实际应用中，应监控不同重排序策略的延迟和效果，通过A/B测试选择最优配置。

## 实际应用示例
假设在一个电商知识图谱中，用户查询“适合送父亲的礼物”。

1.  **配置**：为`NodeSearchConfig`设置`search_methods`为`[bm25, cosine_similarity]`，`reranker`为`cross_encoder`，`reranker_min_score`为0.6。
2.  **执行**：
    *   系统首先通过BM25搜索包含“礼物”、“父亲”等关键词的节点。
    *   同时通过向量搜索找到与“送礼”、“父亲节”等语义相近的节点。
    *   使用RRF将两个列表融合。
    *   将融合后的候选节点（如“领带”、“手表”、“茶叶”）发送给`cross_encoder`模型。
    *   模型评估每个节点与查询的相关性，返回得分。
    *   系统根据得分排序，并过滤掉得分低于0.6的节点。
3.  **结果**：最终返回得分最高的“领带”和“手表”作为推荐结果。